{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.69151476 0.36566605 0.67911265 0.36459452 0.03224102]\n",
      "   [0.58264637 0.6083964  0.33354919 0.47083659 0.88656647]\n",
      "   [0.71385716 0.93339825 0.18347469 0.36288919 0.49170572]\n",
      "   [0.45713387 0.91040412 0.55430057 0.0761062  0.36907429]]\n",
      "\n",
      "  [[0.33530317 0.33933438 0.1593697  0.46531905 0.43938645]\n",
      "   [0.34824519 0.30774724 0.8648023  0.67490156 0.55911608]\n",
      "   [0.12173037 0.98992755 0.80572281 0.68175906 0.68450451]\n",
      "   [0.34820764 0.47756836 0.25889939 0.62141025 0.94308479]]\n",
      "\n",
      "  [[0.71380487 0.28275068 0.76839463 0.7055192  0.43732459]\n",
      "   [0.00165818 0.25647229 0.11308479 0.66844203 0.69137175]\n",
      "   [0.91821178 0.65036089 0.35145554 0.71842155 0.23343241]\n",
      "   [0.9380429  0.85470723 0.50471578 0.67144287 0.44734545]]\n",
      "\n",
      "  [[0.44450301 0.16162256 0.47974544 0.43465014 0.7928301 ]\n",
      "   [0.08062722 0.45028344 0.40730648 0.85934775 0.77973234]\n",
      "   [0.53342635 0.55030729 0.43817064 0.22796363 0.04903722]\n",
      "   [0.52231076 0.35043575 0.17674784 0.27967972 0.80633483]]]]\n",
      "[[[[0. 1. 0. 0. 0.]\n",
      "   [0. 0. 1. 0. 0.]\n",
      "   [0. 0. 1. 0. 0.]\n",
      "   [0. 0. 1. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 1. 0.]\n",
      "   [0. 0. 0. 0. 1.]\n",
      "   [0. 0. 1. 0. 0.]\n",
      "   [0. 0. 1. 0. 0.]]\n",
      "\n",
      "  [[0. 1. 0. 0. 0.]\n",
      "   [0. 0. 1. 0. 0.]\n",
      "   [1. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 1.]\n",
      "   [0. 0. 1. 0. 0.]\n",
      "   [0. 0. 1. 0. 0.]\n",
      "   [1. 0. 0. 0. 0.]]]]\n",
      "[[[1. 2. 2. 2.]\n",
      "  [3. 4. 2. 2.]\n",
      "  [1. 2. 0. 4.]\n",
      "  [4. 2. 2. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "num_classes = 5\n",
    "input = np.random.rand(1, 4, 4, num_classes)\n",
    "output = np.zeros(shape=(1, 4, 4, num_classes))\n",
    "sparse_output = np.zeros(shape=(1, 4, 4))\n",
    "\n",
    "for i in range(0, 4):\n",
    "    for j in range(0, 4):\n",
    "        inti = randint(0, num_classes-1)\n",
    "        sparse_output[0,i,j] = inti\n",
    "        output[0, i, j][inti] = 1\n",
    "\n",
    "\n",
    "print(input)\n",
    "print(output)\n",
    "print(sparse_output)\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(1, 4, 4, num_classes), name=\"myInput\")\n",
    "y = tf.placeholder(tf.float32, shape=(1, 4, 4, num_classes), name=\"myOutput\")\n",
    "sparse_y = tf.placeholder(tf.int32, shape=(1, 4, 4), name=\"my_sparseOutput\")\n",
    "c_weights = tf.constant([0.4,0.2,0.1,0.15,0.15])\n",
    "\n",
    "\n",
    "def cross_entropy(softmaxed_output, correct_output, weights, classes):\n",
    "    with tf.variable_scope(\"cross_entropy\"):\n",
    "        clip_low = 1e-10\n",
    "        clip_high = 1\n",
    "        pixelwise_out = tf.reshape(softmaxed_output, [-1, classes])\n",
    "        # print(f\"shape of pixelwise_out = {pixelwise_out.shape}\")\n",
    "        pixelwise_cor = tf.reshape(correct_output, [-1, classes])\n",
    "        # print(f\"shape of pixelwise_cor = {pixelwise_cor.shape}\")\n",
    "\n",
    "        # return tf.reduce_mean(-tf.reduce_sum(\n",
    "        #     pixelwise_cor * tf.log(\n",
    "        #         tf.clip_by_value(pixelwise_out, clip_value_min=clip_low, clip_value_max=clip_high)),\n",
    "        #     axis=1), name=\"cross_entropy\")\n",
    "\n",
    "        unweighted = pixelwise_cor * tf.log(tf.clip_by_value(pixelwise_out, clip_value_min=clip_low, clip_value_max=clip_high))\n",
    "        # print(f\"shape of unweighted is {unweighted.shape}\"\n",
    "        weighted = tf.divide(unweighted, weights)\n",
    "        # print(f\"shape of weighted is {weighted.shape}\")\n",
    "        each_pixel_loss = -tf.reduce_sum(weighted, axis=1)\n",
    "        # print(f\"shape of each pixels loss = {each_pixel_loss.shape}\")\n",
    "        return tf.reduce_mean(each_pixel_loss, name=\"cross_entropy\")\n",
    "\n",
    "\n",
    "def sparse_cross_entropy(softmaxed_output, correct_output, weights, classes):\n",
    "    with tf.variable_scope(\"cross_entropy\"):\n",
    "        clip_low = 1e-10\n",
    "        clip_high = 1\n",
    "\n",
    "        pixelwise_out = tf.reshape(softmaxed_output, [-1, classes])\n",
    "        print(f\"shape of pixelwise_out = {pixelwise_out.shape}\")\n",
    "        length = int(pixelwise_out.shape[0])\n",
    "        pixelwise_cor = tf.reshape(correct_output, [-1])\n",
    "\n",
    "        indices = tf.stack([tf.constant(np.arange(length)), pixelwise_cor], axis=1)\n",
    "        logit = tf.gather_nd(pixelwise_out, indices)\n",
    "        dim_weights = tf.gather(weights, pixelwise_cor)\n",
    "\n",
    "        unweighted = tf.log(tf.clip_by_value(logit, clip_value_min=clip_low, clip_value_max=clip_high))\n",
    "        weighted = tf.divide(unweighted, dim_weights)\n",
    "        return -tf.reduce_mean(weighted)\n",
    "\n",
    "def pixel_wise_softmax(output_map):\n",
    "    with tf.name_scope(\"pixel_wise_softmax\"):\n",
    "        max_axis = tf.reduce_max(output_map, axis=3, keepdims=True)\n",
    "        exponential_map = tf.exp(output_map - max_axis)\n",
    "        normalize = tf.reduce_sum(exponential_map, axis=3, keepdims=True)\n",
    "        return exponential_map / normalize\n",
    "\n",
    "\n",
    "def unweighted_cost(net_output, true_output, classes):\n",
    "    with tf.variable_scope(\"unweighted_cost\"):\n",
    "        pixelwise_output = tf.reshape(net_output, [-1, classes])\n",
    "        pixelwise_correct = tf.reshape(true_output, [-1, classes])\n",
    "        # print(f\"shape of pixelwise_output = {pixelwise_output.shape}\")\n",
    "        # print(f\"shape of pixelwise_correct = {pixelwise_correct.shape}\")\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "            logits=pixelwise_output, labels=pixelwise_correct))\n",
    "        # print(f\"shape of cost1 = {cost.shape}\")\n",
    "        return cost\n",
    "\n",
    "\n",
    "def sparse_unweighted_cost(net_output, true_output, classes):\n",
    "    with tf.variable_scope(\"unweighted_cost\"):\n",
    "        pixelwise_output = tf.reshape(net_output, [-1, classes])\n",
    "        pixelwise_correct = tf.reshape(true_output, [-1])\n",
    "        # print(f\"shape of pixelwise_output = {pixelwise_output.shape}\")\n",
    "        # print(f\"shape of pixelwise_correct = {pixelwise_correct.shape}\")\n",
    "        cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=pixelwise_output, labels=pixelwise_correct))\n",
    "        # print(f\"shape of cost1 = {cost.shape}\")\n",
    "        return cost\n",
    "\n",
    "\n",
    "def sparse_weighted_cost1(net_output, true_output, weights, classes):\n",
    "    with tf.variable_scope(\"unweighted_cost\"):\n",
    "        pixelwise_output = tf.reshape(net_output, [-1, classes])\n",
    "        pixelwise_correct = tf.reshape(true_output, [-1])\n",
    "\n",
    "        weighted = tf.gather(weights, pixelwise_correct)\n",
    "        # print(f\"shape of pixelwise_output = {pixelwise_output.shape}\")\n",
    "        # print(f\"shape of pixelwise_correct = {pixelwise_correct.shape}\")\n",
    "        cost = tf.reduce_mean(tf.divide(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                logits=pixelwise_output, labels=pixelwise_correct),\n",
    "            weighted))\n",
    "        # print(f\"shape of cost1 = {cost.shape}\")\n",
    "        return cost\n",
    "\n",
    "\n",
    "def weighted_cost(net_output, true_output, weights, classes):\n",
    "    with tf.variable_scope(\"weighted_cost\"):\n",
    "        softmaxed = tf.nn.softmax(net_output, axis=3)\n",
    "        cost = cross_entropy(softmaxed, true_output, weights, classes)\n",
    "        # print(f\"shape of softmaxed = {softmaxed.shape}\")\n",
    "        # print(f\"shape of cost2 = {cost.shape}\")\n",
    "        return cost\n",
    "\n",
    "\n",
    "def sparse_weighted_cost2(net_output, true_output, weights, classes):\n",
    "    with tf.variable_scope(\"weighted_cost\"):\n",
    "        softmaxed = tf.nn.softmax(net_output, axis=3)\n",
    "        cost = sparse_cross_entropy(softmaxed, true_output, weights, classes)\n",
    "        # print(f\"shape of softmaxed = {softmaxed.shape}\")\n",
    "        # print(f\"shape of cost2 = {cost.shape}\")\n",
    "        return cost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onehot unweighted cost = 1.6733899116516113\n",
      "onehot weighted cost = 12.96287727355957\n",
      "sparse unweighted cost = 1.6733899116516113\n",
      "sparse weighted cost = 12.96287727355957\n",
      "shape of pixelwise_out = (16, 5)\n",
      "my own sparse weighted cost = [12.962877]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    onehot_u_cost, onehot_w_cost = sess.run([unweighted_cost(x,y,num_classes), \n",
    "                                             weighted_cost(x, y, c_weights, num_classes)], \n",
    "                                            feed_dict={x: input, y: output})\n",
    "    print(f\"onehot unweighted cost = {onehot_u_cost}\")\n",
    "    print(f\"onehot weighted cost = {onehot_w_cost}\")\n",
    "    sparse_u_cost, sparse_w_cost = sess.run([sparse_unweighted_cost(x, sparse_y, num_classes), \n",
    "                                             sparse_weighted_cost1(x, sparse_y, c_weights, num_classes)],\n",
    "                                            feed_dict={x: input, sparse_y: sparse_output})\n",
    "    print(f\"sparse unweighted cost = {sparse_u_cost}\")\n",
    "    print(f\"sparse weighted cost = {sparse_w_cost}\")\n",
    "    sparse_w_cost2 =sess.run([sparse_weighted_cost2(x, sparse_y, c_weights, num_classes)],\n",
    "                            feed_dict={x: input, sparse_y: sparse_output})\n",
    "    print(f\"my own sparse weighted cost = {sparse_w_cost2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
