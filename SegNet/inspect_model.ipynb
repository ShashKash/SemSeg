{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import skimage\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow.python.tools import inspect_checkpoint as chkp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_ckp = tf.train.latest_checkpoint('./')\n",
    "chkp.print_tensors_in_checkpoint_file(latest_ckp, all_tensors=True, tensor_name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"cat.jpg\")\n",
    "img1 = np.array(img)\n",
    "print(img1.shape)\n",
    "img2 = skimage.transform.resize(img1, output_shape=(224,224,3))\n",
    "print(img2.shape)\n",
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [123.68, 116.78, 103.94]\n",
    "img2 = img2 - mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_default_graph()\n",
    "\n",
    "input = tf.placeholder(tf.float32, shape=(None, 224, 224, 3), name=\"myInput\")\n",
    "\n",
    "def weight_initializer(stddev=0.1, he=False):\n",
    "    if (he == True):\n",
    "        return tf.initializers.he_normal()\n",
    "    else:\n",
    "        return tf.truncated_normal_initializer(mean=0, stddev=stddev)\n",
    "\n",
    "with tf.variable_scope(\"vgg_16/conv1\", reuse=tf.AUTO_REUSE):\n",
    "    W1 = tf.get_variable(\"conv1_1/weights\", [3, 3, input.shape[3], 64],\n",
    "                         initializer=weight_initializer(np.sqrt(2 / (3 ** 2 * 64))))\n",
    "    W2 = tf.get_variable(\"conv1_2/weights\", [3, 3, 64, 64],\n",
    "                         initializer=weight_initializer(np.sqrt(2 / (3 ** 2 * 64))))\n",
    "    b1 = tf.get_variable(\"conv1_1/biases\", [64],\n",
    "                         initializer=tf.constant_initializer(0.1))\n",
    "    b2 = tf.get_variable(\"conv1_2/biases\", [64],\n",
    "                         initializer=tf.constant_initializer(0.1))\n",
    "#         tf.summary.histogram(\"weights1\", W1)\n",
    "#         tf.summary.histogram(\"weights2\", W2)\n",
    "#         tf.summary.histogram(\"biases1\", b1)\n",
    "#         tf.summary.histogram(\"biases2\", b2)\n",
    "    conv = tf.nn.conv2d(input, filter=W1, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    conv = tf.nn.relu(conv + b1)\n",
    "#         print(conv_block.shape)\n",
    "    conv = tf.nn.conv2d(conv, filter=W2, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "#         print(conv_block.shape)\n",
    "#         tf.summary.histogram(\"pre_relu\", pre_relu)\n",
    "    conv = tf.nn.relu(conv + b2)\n",
    "\n",
    "conv = tf.nn.max_pool(conv, ksize=[1, 2, 2, 1],\n",
    "                      strides=[1, 2, 2, 1],\n",
    "                      padding=\"VALID\")\n",
    "\n",
    "with tf.variable_scope(\"vgg_16/conv2\", reuse=tf.AUTO_REUSE):\n",
    "    W3 = tf.get_variable(\"conv2_1/weights\", [3, 3, 64, 128],\n",
    "                         initializer=weight_initializer(np.sqrt(2 / (3 ** 2 * 128))))\n",
    "    W4 = tf.get_variable(\"conv2_2/weights\", [3, 3, 128, 128],\n",
    "                         initializer=weight_initializer(np.sqrt(2 / (3 ** 2 * 128))))\n",
    "    b3 = tf.get_variable(\"conv2_1/biases\", [128],\n",
    "                         initializer=tf.constant_initializer(0.1))\n",
    "    b4 = tf.get_variable(\"conv2_2/biases\", [128],\n",
    "                         initializer=tf.constant_initializer(0.1))\n",
    "#         tf.summary.histogram(\"weights1\", W1)\n",
    "#         tf.summary.histogram(\"weights2\", W2)\n",
    "#         tf.summary.histogram(\"biases1\", b1)\n",
    "#         tf.summary.histogram(\"biases2\", b2)\n",
    "    conv = tf.nn.conv2d(conv, filter=W3, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    conv = tf.nn.relu(conv + b3)\n",
    "#         print(conv_block.shape)\n",
    "    conv = tf.nn.conv2d(conv, filter=W4, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    conv = tf.nn.relu(conv + b4)\n",
    "    \n",
    "conv = tf.nn.max_pool(conv, ksize=[1, 2, 2, 1],\n",
    "                      strides=[1, 2, 2, 1],\n",
    "                      padding=\"VALID\")\n",
    "\n",
    "with tf.variable_scope(\"vgg_16/conv3\", reuse=tf.AUTO_REUSE):\n",
    "    W5 = tf.get_variable(\"conv3_1/weights\", [3, 3, 128, 256],\n",
    "                         initializer=weight_initializer(np.sqrt(2 / (3 ** 2 * 256))))\n",
    "    W6 = tf.get_variable(\"conv3_2/weights\", [3, 3, 256, 256],\n",
    "                         initializer=weight_initializer(np.sqrt(2 / (3 ** 2 * 256))))\n",
    "    W7 = tf.get_variable(\"conv3_3/weights\", [3, 3, 256, 256],\n",
    "                         initializer=weight_initializer(np.sqrt(2 / (3 ** 2 * 256))))\n",
    "    b5 = tf.get_variable(\"conv3_1/biases\", [256],\n",
    "                         initializer=tf.constant_initializer(0.1))\n",
    "    b6 = tf.get_variable(\"conv3_2/biases\", [256],\n",
    "                         initializer=tf.constant_initializer(0.1))\n",
    "    b7 = tf.get_variable(\"conv3_3/biases\", [256],\n",
    "                         initializer=tf.constant_initializer(0.1))\n",
    "#         tf.summary.histogram(\"weights1\", W1)\n",
    "#         tf.summary.histogram(\"weights2\", W2)\n",
    "#         tf.summary.histogram(\"biases1\", b1)\n",
    "#         tf.summary.histogram(\"biases2\", b2)\n",
    "    conv = tf.nn.conv2d(conv, filter=W5, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    conv = tf.nn.relu(conv + b5)\n",
    "#         print(conv_block.shape)\n",
    "    conv = tf.nn.conv2d(conv, filter=W6, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    conv = tf.nn.relu(conv + b6)\n",
    "#         print(conv_block.shape)\n",
    "    conv = tf.nn.conv2d(conv, filter=W7, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    conv = tf.nn.relu(conv + b7)\n",
    "    \n",
    "conv = tf.nn.max_pool(conv, ksize=[1, 2, 2, 1],\n",
    "                      strides=[1, 2, 2, 1],\n",
    "                      padding=\"VALID\")\n",
    "\n",
    "with tf.variable_scope(\"vgg_16/conv4\", reuse=tf.AUTO_REUSE):\n",
    "    W8 = tf.get_variable(\"conv4_1/weights\", [3, 3, 256, 512],\n",
    "                         initializer=weight_initializer(np.sqrt(2 / (3 ** 2 * 512))))\n",
    "    W9 = tf.get_variable(\"conv4_2/weights\", [3, 3, 512, 512],\n",
    "                         initializer=weight_initializer(np.sqrt(2 / (3 ** 2 * 512))))\n",
    "    W10 = tf.get_variable(\"conv4_3/weights\", [3, 3, 512, 512],\n",
    "                         initializer=weight_initializer(np.sqrt(2 / (3 ** 2 * 512))))\n",
    "    b8 = tf.get_variable(\"conv4_1/biases\", [512],\n",
    "                         initializer=tf.constant_initializer(0.1))\n",
    "    b9 = tf.get_variable(\"conv4_2/biases\", [512],\n",
    "                         initializer=tf.constant_initializer(0.1))\n",
    "    b10 = tf.get_variable(\"conv4_3/biases\", [512],\n",
    "                         initializer=tf.constant_initializer(0.1))\n",
    "#         tf.summary.histogram(\"weights1\", W1)\n",
    "#         tf.summary.histogram(\"weights2\", W2)\n",
    "#         tf.summary.histogram(\"biases1\", b1)\n",
    "#         tf.summary.histogram(\"biases2\", b2)\n",
    "    conv = tf.nn.conv2d(conv, filter=W8, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    conv = tf.nn.relu(conv + b8)\n",
    "#         print(conv_block.shape)\n",
    "    conv = tf.nn.conv2d(conv, filter=W9, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    conv = tf.nn.relu(conv + b9)\n",
    "#         print(conv_block.shape)\n",
    "    conv = tf.nn.conv2d(conv, filter=W10, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    conv = tf.nn.relu(conv + b10)\n",
    "    \n",
    "conv = tf.nn.max_pool(conv, ksize=[1, 2, 2, 1],\n",
    "                      strides=[1, 2, 2, 1],\n",
    "                      padding=\"VALID\")\n",
    "\n",
    "with tf.variable_scope(\"vgg_16/conv5\", reuse=tf.AUTO_REUSE):\n",
    "    W11 = tf.get_variable(\"conv5_1/weights\", [3, 3, 512, 512],\n",
    "                         initializer=weight_initializer(np.sqrt(2 / (3 ** 2 * 512))))\n",
    "    W12 = tf.get_variable(\"conv5_2/weights\", [3, 3, 512, 512],\n",
    "                         initializer=weight_initializer(np.sqrt(2 / (3 ** 2 * 512))))\n",
    "    W13 = tf.get_variable(\"conv5_3/weights\", [3, 3, 512, 512],\n",
    "                         initializer=weight_initializer(np.sqrt(2 / (3 ** 2 * 512))))\n",
    "    b11 = tf.get_variable(\"conv5_1/biases\", [512],\n",
    "                         initializer=tf.constant_initializer(0.1))\n",
    "    b12 = tf.get_variable(\"conv5_2/biases\", [512],\n",
    "                         initializer=tf.constant_initializer(0.1))\n",
    "    b13 = tf.get_variable(\"conv5_3/biases\", [512],\n",
    "                         initializer=tf.constant_initializer(0.1))\n",
    "#         tf.summary.histogram(\"weights1\", W1)\n",
    "#         tf.summary.histogram(\"weights2\", W2)\n",
    "#         tf.summary.histogram(\"biases1\", b1)\n",
    "#         tf.summary.histogram(\"biases2\", b2)\n",
    "    conv = tf.nn.conv2d(conv, filter=W11, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    conv = tf.nn.relu(conv + b11)\n",
    "#         print(conv_block.shape)\n",
    "    conv = tf.nn.conv2d(conv, filter=W12, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    conv = tf.nn.relu(conv + b12)\n",
    "#         print(conv_block.shape)\n",
    "    conv = tf.nn.conv2d(conv, filter=W13, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    conv = tf.nn.relu(conv + b13)\n",
    "    \n",
    "conv = tf.nn.max_pool(conv, ksize=[1, 2, 2, 1],\n",
    "                      strides=[1, 2, 2, 1],\n",
    "                      padding=\"VALID\")\n",
    "\n",
    "print(conv.shape)\n",
    "middle_output = conv\n",
    "\n",
    "conv = tf.reshape(conv, [-1, 7 * 7 * 512])\n",
    "print(conv.shape)\n",
    "\n",
    "with tf.variable_scope(\"vgg_16/fc6\", reuse=tf.AUTO_REUSE):\n",
    "    W14 = tf.get_variable(\"weights\", [7, 7, 512, 4096],\n",
    "                         initializer=weight_initializer(np.sqrt(2 / ((7 * 7 * 512) ** 2 * 4096))))\n",
    "    Wa = tf.reshape(W14, [-1, 4096])\n",
    "    b14 = tf.get_variable(\"biases\", [4096],\n",
    "                         initializer=tf.constant_initializer(0.1))\n",
    "    conv = tf.nn.relu(tf.matmul(conv, Wa) + b14)\n",
    "#     conv = tf.nn.conv2d(conv, filter=W14, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "#     conv = tf.nn.relu(conv + b14)\n",
    "#         print(conv_block.shape)\n",
    "print(conv.shape)\n",
    "\n",
    "with tf.variable_scope(\"vgg_16/fc7\", reuse=tf.AUTO_REUSE):\n",
    "    W15 = tf.get_variable(\"weights\", [1, 1, 4096, 4096],\n",
    "                         initializer=weight_initializer(np.sqrt(2 / (4096 ** 2 * 4096))))\n",
    "    Wb = tf.squeeze(W15, [0, 1])\n",
    "    b15 = tf.get_variable(\"biases\", [4096],\n",
    "                         initializer=tf.constant_initializer(0.1))\n",
    "    conv = tf.nn.relu(tf.matmul(conv, Wb) + b15)\n",
    "#     conv = tf.nn.conv2d(conv, filter=W14, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "#     conv = tf.nn.relu(conv + b14)\n",
    "#     print(conv_block.shape)\n",
    "print(conv.shape)\n",
    "\n",
    "with tf.variable_scope(\"vgg_16/fc8\", reuse=tf.AUTO_REUSE):\n",
    "    W16 = tf.get_variable(\"weights\", [1, 1, 4096, 1000],\n",
    "                         initializer=weight_initializer(np.sqrt(2 / (4096 ** 2 * 1000))))\n",
    "    Wc = tf.squeeze(W16, [0, 1])\n",
    "    b16 = tf.get_variable(\"biases\", [1000],\n",
    "                         initializer=tf.constant_initializer(0.1))\n",
    "    logits = tf.matmul(conv, Wc) + b16\n",
    "#     conv = tf.nn.conv2d(conv, filter=W16, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "#     logits = conv + b16\n",
    "#     print(conv_block.shape)\n",
    "\n",
    "print(logits.shape)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver({\"vgg_16/conv1/conv1_1/biases\": b1,\n",
    "                           \"vgg_16/conv1/conv1_1/weights\": W1,\n",
    "                           \"vgg_16/conv1/conv1_2/biases\": b2,\n",
    "                           \"vgg_16/conv1/conv1_2/weights\": W2,\n",
    "                           \"vgg_16/conv2/conv2_1/biases\": b3,\n",
    "                           \"vgg_16/conv2/conv2_1/weights\": W3,\n",
    "                           \"vgg_16/conv2/conv2_2/biases\": b4,\n",
    "                           \"vgg_16/conv2/conv2_2/weights\": W4,\n",
    "                           \"vgg_16/conv3/conv3_1/biases\": b5,\n",
    "                           \"vgg_16/conv3/conv3_1/weights\": W5,\n",
    "                           \"vgg_16/conv3/conv3_2/biases\": b6,\n",
    "                           \"vgg_16/conv3/conv3_2/weights\": W6,\n",
    "                           \"vgg_16/conv3/conv3_3/biases\": b7,\n",
    "                           \"vgg_16/conv3/conv3_3/weights\": W7,\n",
    "                           \"vgg_16/conv4/conv4_1/biases\": b8,\n",
    "                           \"vgg_16/conv4/conv4_1/weights\": W8,\n",
    "                           \"vgg_16/conv4/conv4_2/biases\": b9,\n",
    "                           \"vgg_16/conv4/conv4_2/weights\": W9,\n",
    "                           \"vgg_16/conv4/conv4_3/biases\": b10,\n",
    "                           \"vgg_16/conv4/conv4_3/weights\": W10,\n",
    "                           \"vgg_16/conv5/conv5_1/biases\": b11,\n",
    "                           \"vgg_16/conv5/conv5_1/weights\": W11,\n",
    "                           \"vgg_16/conv5/conv5_2/biases\": b12,\n",
    "                           \"vgg_16/conv5/conv5_2/weights\": W12,\n",
    "                           \"vgg_16/conv5/conv5_3/biases\": b13,\n",
    "                           \"vgg_16/conv5/conv5_3/weights\": W13,\n",
    "                           \"vgg_16/fc6/biases\": b14,\n",
    "                           \"vgg_16/fc6/weights\": W14,\n",
    "                           \"vgg_16/fc7/biases\": b15,\n",
    "                           \"vgg_16/fc7/weights\": W15,\n",
    "                           \"vgg_16/fc8/biases\": b16,\n",
    "                           \"vgg_16/fc8/weights\": W16})\n",
    "    \n",
    "    saver.restore(sess, \"./vgg/vgg_16.ckpt\")\n",
    "    \n",
    "    middle, labels = sess.run([middle_output, prediction], feed_dict={input: np.expand_dims(img2, axis=0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probs = labels[0]\n",
    "print(f\"label index = {np.argmax(predicted_probs)}\")\n",
    "print(f\"label probability = {predicted_probs[np.argmax(labels[0])]}\")\n",
    "class_111_idx = np.argmax(middle[0][4,2,:])\n",
    "class_111_mask = middle[0][:,:,441]\n",
    "print(class_111_mask)\n",
    "print(class_111_idx)\n",
    "plt.imshow(class_111_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
